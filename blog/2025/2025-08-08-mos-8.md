---
layout: post
title: Mind on Statistics (6th. Ed) Chapter 8 - Random Variables
author: Arpon Sarker
date: 2025-08-08 12:45:32
categories: [statistics]
tags: [mathematics, statistics]
---

## Introduction
- Distinguish between discrete and continuous random variables
- Compute probabilities of events for a discrete random variable using a probability distribution function
- Explain the meaning of expected value for a discrete random variable
- Calculate the mean, standard deviation, and probabilities for binomial random variables
- Describe how to compute probabilities for continuous random variables, including the special case of uniform random variables.
- Calculate probabilities and percentiles for normal random variables
- Calculate parameters (means and standard deviations) for linear combinations and transformations of random variables

## Random Variable

> **Random variable:** assigns a number to each outcome of a random circumstance. Equivalently, a random variable assigns a number to each unit in the population. Either discrete or continuous.

For discrete random variables, we can find probabilities for exact outcomes but for continuous random variables we can only find probabilities of intervals.

> **Probability distribution function (pdf)** for a discrete random variable $X$ is a table/rule that assigns a probability to each possible value of the random variable $X$. 

> **Cumulative Probability:** the probability that a variable $X$ is less than or equal to a particular value

> **Cumulative Distribution Function:** is a table/rule that gives $P(X\leq k)$ for any number $k$

## Expectations for Random Variables

> **Expected value** of a random variable $X$ is the mean value of the variable in the sample space or population of possible outcomes. It can also be interpreted as the mean value that would be obtained from an infinite number of observations of the random variable.

Expected value of discrete R.V.
$$
E(X) = \sum{x_ip_i}
$$
Std. Dev. of discrete R.V.
$$
\sigma = \sqrt{\sum{(x_i-\mu)^2p_i}}
$$

## Binomial Random Variable

A *binomial experiment* is defined by:
- There are $n$ trials
- There are two possible outcomes for each trial
- The outcomes are independent for each trial
- The probability of a success remains the same from one trial to the next, denoted $p$

$$
P(X=k) = \frac{n!}{k!(n-k)!}p^k(1-p)^{n-k}
$$

The above formula has a combinatorial component which counts how many combinations of successes and failures are there divided by repeats and the exponent part is the associated probability for that sequence of failures and successes.

Mean of binomial R.V.
$$
\mu = np
$$
Std. Dev. of binomial R.V.
$$
\sigma = \sqrt{np(1-p)}
$$

## Continuous Random Variables

### Uniform Random Variables

### Normal Random Variables

Useful rules:
$$
P(X>a) = 1-P(X\leq a)\\
P(a<X<b) = P(X\leq b) - P(X\leq a)\\
P(X>\mu + d) = P(X < \mu - d) 
$$

## Approximating Binomial Distribution Probabilities

The normal approximation to the binomial distribution is that if $X$ is a binomial random variable based on $n$ trials with success probability $p$ and if $n$ is sufficiently large, then $X$ is also approximately a normal random variable. Use the mean and std. dev. formulas for binomial random variable as normal parameters.

Conditions for above:
$$
np \geq 10\\
n(1-p) \geq 10
$$

## Linear Combinations and Linear Transformations of R.V.

Linear Combination Rules:
$$
L =aX + bY + \ldots\\
\textrm{mean}(L) = a\textrm{mean}(X) + b\textrm{mean}(Y) + \ldots\\
\textrm{var}(L) = a^2\textrm{var}(X) + b^2\textrm{var}(Y) + \ldots
$$

Linear Transformation rules:
$$
Y = a + bX\\
\textrm{mean}(X) = a + b\textrm{mean}(Y)\\
\textrm{sd}(Y) = |b|
$$
